{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fa4a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "import PyPDF2\n",
    "import textract\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a223a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "skill_pattern_path = \"jz_skill_patterns.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b0d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = \"DeGuzman_Karl_CV.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "231a43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObj = open(pdf,'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\"\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d+','',text)\n",
    "text = re.sub(r'\\n', '', text)\n",
    "text = text.translate(str.maketrans('','',string.punctuation))\n",
    "text = text.replace('â€¢', '')\n",
    "text = text.replace('-', '')\n",
    "text = text.replace('  ', ' ')\n",
    "text = text.replace('   ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a2488c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'entity_ruler']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(skill_pattern_path)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c7e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills(text):\n",
    "    doc = nlp(text)\n",
    "    myset = []\n",
    "    subset = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"SKILL\":\n",
    "            subset.append(ent.text)\n",
    "    myset.append(subset)\n",
    "    return subset\n",
    "\n",
    "\n",
    "def unique_skills(x):\n",
    "    return list(set(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "831fc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = list(dict.fromkeys(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c78631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28d213f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m skills \u001b[38;5;241m=\u001b[39m get_skills(text)\n\u001b[1;32m----> 2\u001b[0m skils \u001b[38;5;241m=\u001b[39m skills\u001b[38;5;241m.\u001b[39mapply(unique_skills)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "skills = get_skills(text)\n",
    "skils = skills.apply(unique_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf3f5fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m clean \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      3\u001b[0m     review \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(@[A-Za-z0-9]+)|([^0-9A-Za-z \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m])|(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+)|^rt|http.+?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResume_str\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i],\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     review \u001b[38;5;241m=\u001b[39m review\u001b[38;5;241m.\u001b[39mlower()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "clean = []\n",
    "for i in range(data.shape[0]):\n",
    "    review = re.sub(\n",
    "        '(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"',\n",
    "        \" \",\n",
    "        data[\"Resume_str\"].iloc[i],\n",
    "    )\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lm = WordNetLemmatizer()\n",
    "    review = [\n",
    "        lm.lemmatize(word)\n",
    "        for word in review\n",
    "        if not word in set(stopwords.words(\"english\"))\n",
    "    ]\n",
    "    review = \" \".join(review)\n",
    "    clean.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665223bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
